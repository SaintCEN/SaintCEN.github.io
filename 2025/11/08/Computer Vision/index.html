<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Computer Vision, Sa1ntCHENの小窝">
    <meta name="description" content="Computer Vision(CV)

参考Stanford CS231课程，我的计算机视觉基础笔记
有Machine Learning和Deep Learning基础食用更佳

Classification
分类任务在机器学">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <meta name="referrer" content="no-referrer-when-downgrade">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Computer Vision | Sa1ntCHENの小窝</title>
    <link rel="icon" type="image/png" href="/favicon.png">
    
    <style>
        body{
            background-image: url(/medias/bg.jpg);
            background-repeat: no-repeat;
            background-size: 100% 100%;
            background-attachment: fixed;
            background-position: center center;
        }
    </style>


    
    <!-- bg-cover style     -->



        <link rel="stylesheet" type="text/css"
            href="/libs/awesome/css/all.min.css">
        <link rel="stylesheet" type="text/css"
            href="/libs/materialize/materialize.min.css">
        <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
        <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
        <link rel="stylesheet" type="text/css" href="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/css/lightgallery.css">
        <link rel="stylesheet" type="text/css" href="/css/matery.css">
        <link rel="stylesheet" type="text/css" href="/css/my.css">
        <link rel="stylesheet" type="text/css" href="/css/dark.css"
            media="none" onload="if(media!='all')media='all'">

        


    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
    <link rel="stylesheet" href="/css/post.css">



            
    
        <link rel="stylesheet" type="text/css" href="/css/reward.css">
    


    <script src="/libs/jquery/jquery-3.6.0.min.js"></script>

<meta name="generator" content="Hexo 8.0.0"><link rel="alternate" href="/atom.xml" title="Sa1ntCHENの小窝" type="application/atom+xml">
</head>


<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Sa1ntCHENの小窝</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
  <li>
    <a href="javascript:;" class="waves-effect waves-light" onclick="switchNightMode()" title="深色/浅色模式" >
      <i id="sum-moon-icon" class="fas fa-sun" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Sa1ntCHENの小窝</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/SaintCEN" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #1976D2;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/SaintCEN" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    

<div class="bg-cover pd-header post-cover">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Computer Vision</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                    <div class="article-tag">
                        
                            <a href="/tags/AI/">
                                <span class="chip bg-color">AI</span>
                            </a>
                        
                    </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                    <div class="post-cate">
                        <i class="fas fa-bookmark fa-fw icon-category"></i>
                        
                            <a href="/categories/%E7%AC%94%E8%AE%B0/" class="post-category">
                                笔记
                            </a>
                        
                    </div>
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2025-11-08
                </div>
                

                

                

                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.min.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="computer-visioncv">Computer Vision(CV)</h1>
<blockquote>
<p>参考Stanford CS231课程，我的计算机视觉基础笔记</p>
<p>有Machine Learning和Deep Learning基础食用更佳</p>
</blockquote>
<h2 id="classification">Classification</h2>
<p>分类任务在机器学习中很常见，对于视觉任务，即是把图像(<code>picture</code>)归为标签(<code>label</code>)，例如：{<code>cat</code>,<code>dog</code>,<code>car</code>}，我们需要找到某种从图像到标签的逻辑关系，并利用这种逻辑关系进行预测。</p>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>images<span class="token punctuation">,</span> labels<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment"># Machine learning</span>
	<span class="token keyword">return</span> model<span class="token punctuation">;</span>

<span class="token keyword">def</span> <span class="token function">precict</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_images<span class="token punctuation">)</span><span class="token punctuation">:</span>
	<span class="token comment"># Use model to predict labels</span>
	<span class="token keyword">return</span> test_labels</code></pre>
<p>计算机能读懂的是数字，而不是图像本身。一张图像本质上是像素点的排列，每个像素点有不同的取值，比如在<code>RGB</code>图像中，红/绿/蓝分别分别可以取值<code>[0,255]</code>，一张<code>800*600</code>大小的图像就有<code>800*600*3</code>个参数，我们研究的本质还是如何对数据进行处理。</p>
<p>但是，分类任务还会遇到许多问题：<code>semantic gap</code>（语义鸿沟）/<code>viewpoint variation</code>（视角多样）/<code>illumination</code>（光照）/<code>deformation</code>（变形）/<code>occlusion</code>（遮挡）/<code>background clutter</code>（背景）/<code>intraclass variation</code>（类内变异）/…</p>
<p>一般来说，会依据具体的任务设计预处理/模块/网络/正则化，通过训练和调参来缓解这些问题。分类任务作为最基本的任务能衍生许多方法，成为了我们研究视觉任务的抓手。</p>
<h3 id="k-nearest-neighborknn">K-Nearest Neighbor(KNN)</h3>
<p>俗话说“物以类聚，人以群分”，如果有一个很大的样本库（如<code>CIFAR-10</code>），里面有各种类型的图像，我们可以通过比较需要分类的图像它们之间的相似度来选出最有可能的类别。</p>
<p>最直接的我们可以对图像的每个像素点进行直接比较<span class="math inline"><em>d</em><sub>1</sub>(<em>I</em><sub>1</sub>, <em>I</em><sub>2</sub>) = ∑<sub><em>p</em></sub>|<em>I</em><sub>1</sub><sup><em>p</em></sup> − <em>I</em><sub>2</sub><sup><em>p</em></sup>|</span>。</p>
<p>当然，按照<code>KNN</code>的想法，我们有欧式距离<span class="math inline">$d_2(I_1,I_2)=\sqrt{\sum_p(I_1^p-I_2^p)}$</span>衡量不同图像的差异，并且设置超参数（<code>hypermarameters</code>），对需要分类的图像距离最近的<span class="math inline"><em>k</em></span>个类型进行投票，票数最高的就是预测的类别，超参数<span class="math inline"><em>k</em></span>往往需要通过实验获得。实验设置上我们往往要分<code>train</code>(训练集)/<code>validation</code>(评估集)/<code>test</code>(测试集)，评估集的作用主要是惩罚训练集的过拟合，而测试集检验了模型的泛化能力。</p>
<p>但是，<code>KNN</code>会有两个致命的问题：一个是随着参数量上升导致的维度爆炸，另一个是过于关注像素点而忽略图像某个区域的特征，无法表示视觉感知的差异。</p>
<h3 id="linear-classification">Linear-Classification</h3>
<p>另一种方式是，我们为图像和标签建立一个函数关系，最简单的就是线性函数。
<span class="math display"><em>f</em>(<em>x</em>, <em>w</em>) = <em>w</em><em>x</em> + <em>b</em></span>
例如，我们要分<code>10</code>种类型，通过线性分类模型，我们最后会得到一个<code>10*1</code>的矩阵，每个元素代表“该分类的评分”，我们把<code>32*32*3</code>的<code>RGB</code>图像展平成一个<code>3072*1</code>的向量，根据矩阵运算法则，我们需要构建一个<code>10*3072</code>的<span class="math inline"><em>w</em></span>矩阵，和一个<code>10*1</code>的<span class="math inline"><em>b</em></span>向量，当我们输入图像的向量后，输出<code>10</code>个评分，值最大的就是预测的类别。而<span class="math inline"><em>w</em></span>和<span class="math inline"><em>b</em></span>参数的矩阵需要通过对神经网络进行训练获得。然而，线性关系还是很难捕捉图像和标签之间的复杂关系，引入非线性关系是必要的。</p>
<h3 id="convolutionnal-nueral-networks">Convolutionnal Nueral
Networks</h3>
<p>为了捕捉图像和标签之间的非线性关系，我们引入了卷积神经网络。卷积神经网络的结构与常规的神经网络并没有区别，关键在于“卷积层”可以提取“图像特征”，也因此被广泛用于分类/识别/理解等视觉任务。</p>
<p><strong>Convolution</strong></p>
<p>重复上面的例子，假设现在有一个全连接层，输入是<code>3072*1</code>的图像矩阵，通过<code>10*3072</code>个权重的神经元，经过<code>activation</code>输出了<code>1*10</code>的标签矩阵。但是直接展平成一维矩阵会丢失掉区域的结构信息，我们能不能保持矩阵原先的形状，同时又能赋予其权重呢？</p>
<p>因此，我们引入了卷积核(<code>filter</code>)的概念。在这个例子中我们设定大小为<code>5*5*3</code>，赋予其<code>75</code>个权重，在卷积核和图像块之间进行点积运算，即将卷积核的权重和图像的像素值相乘加上偏置值（<span class="math inline"><em>w</em><sup><em>T</em></sup><em>x</em> + <em>b</em></span>），得到一个数值。注意，在点积的实际操作中，卷积核会被展平成一维向量进行运算（参考<code>numpy</code>的原理）。</p>
<p>如果将卷积核逐步移动遍历整个<code>32*32*3</code>的图像，最后会得到<code>28*28*1</code>的<code>activation maps</code>，如果用不同的<span class="math inline"><em>n</em></span>个卷积核就会得到<span class="math inline"><em>n</em></span>层（不同的卷积核有不同的权重，可以理解为提取不同的特征）。</p>
<p>在卷积操作之后，我们往往会连接激活函数并输入新的卷积神经元，卷积核尺寸随新的输入改变，经历多次卷积，图像特征也会从低阶到复杂。本质上，每一次卷积操作就是一个神经元，有几个卷积核神经元就有多少层，通过降低平面尺寸提取了特征，但过多的特征提取也会导致信息的丢失。</p>
<p>卷积核遍历的时候我们可以设置一些参数，比如<code>stride</code>（步长），对于<code>7*7</code>图像，<code>3*3</code>卷积核，步长为<code>1</code>会得到<code>5*5</code>，而步长为<code>2</code>会得到<code>3*3</code>，但步长为<code>3</code>会无法对齐，为了解决这个问题，我们会引入<code>padding</code>，在边缘处补上人为设定数值的边框（一般为<code>0</code>/镜像值等），让卷积核移动时可以填满图像的边缘。在实际操作中，我们往往把卷积核的步长设为<code>1</code>。</p>
<p><code>map</code>的边长计算公式总结如下：<span class="math inline"><em>x</em> = (<em>N</em> − <em>F</em> + 2 * <em>p</em><em>a</em><em>d</em><em>d</em><em>i</em><em>n</em><em>g</em>)/<em>s</em><em>t</em><em>r</em><em>i</em><em>d</em><em>e</em> + 1</span></p>
<p><strong>Pooling</strong></p>
<p>如果网络中只有卷积层，我们的参数量依旧过大，不利于计算，我们需要引入平面的池化操作。</p>
<p>例如，<code>Max Pooling</code>即最大池化，设定一定尺寸的池化核，无交叉铺满图像块（如果大小超出边缘也无所谓，取最大即可，因此不需要<code>padding</code>），在每一个池化核内取最大值，代表“图像任意区域的受激程度”，既降低了数据的维度，又保留了每一个图像块的特征。一般我们会设置核大小为<code>2*2</code>，步长为<code>2</code>。</p>
<p>至此，我们得到了最基本的卷积神经网络循环结构<code>Conv+ReLU+Pool</code>，但具体的网络结构和超参数设置往往需要通过实验对比获得。
## CNN</p>
<p><code>CNN</code>本质上结合了深度学习和卷积神经网络的思想，通过增加深度和特征提取来处理视觉任务。</p>
<h3 id="alexnet">AlexNet</h3>
<p>最早的<code>CNN</code>，根据实验得出了参数良好的卷积神经网络。<code>CNN</code>的原理我们已在上文提及，一般还会有<code>Linear</code>层控制数据的维度。</p>
<p><img src="/2025/11/08/Computer%20Vision/1.png"></p>
<h3 id="vggnet">VGGNet</h3>
<p>设计时对<code>AlexNet</code>改进，增加了网络深度的同时减少了参数量。核心即用多层小卷积核（<code>3×3</code>）堆叠，替代大卷积核（<code>7×7</code>、<code>5×5</code>），在保持感受野的同时大幅减少参数，还顺手多了非线性层数。<img src="/2025/11/08/Computer%20Vision/2.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/3.png"></p>
<h3 id="nin">NiN</h3>
<p><code>Network in NetWork</code>，最早提出了<code>bottleneck layers</code>的概念，启发了后续网络的局部拓扑结构。简单讲，它在空间卷积后用<code>1*1</code>卷积压缩通道、再用<code>1*1</code>扩展映射回去，用来在保持特征信息的同时减少参数量和计算量，还增加了非线性。</p>
<p><img src="/2025/11/08/Computer%20Vision/9.png"></p>
<h3 id="googlenet">GoogLeNet</h3>
<p>在增加深度的基础上加速了计算效率，提出了<code>Inception module</code>局部拓扑结构，用到了<code>bottleneck layers</code>的想法。</p>
<table>
<colgroup>
<col style="width: 5%">
<col style="width: 58%">
<col style="width: 35%">
</colgroup>
<thead>
<tr>
<th>分支</th>
<th style="text-align: center;">结构</th>
<th style="text-align: center;">功能</th>
</tr>
</thead>
<tbody>
<tr>
<td>①</td>
<td style="text-align: center;"><span class="math inline">1 × 1</span>
卷积</td>
<td style="text-align: center;">提取局部特征、线性变换通道</td>
</tr>
<tr>
<td>②</td>
<td style="text-align: center;"><span class="math inline">1 × 1</span> →
<span class="math inline">3 × 3</span> 卷积</td>
<td style="text-align: center;">先降维、再提取中尺度特征</td>
</tr>
<tr>
<td>③</td>
<td style="text-align: center;"><span class="math inline">1 × 1</span> →
<span class="math inline">5 × 5</span> 卷积</td>
<td style="text-align: center;">先降维、再提取大尺度特征</td>
</tr>
<tr>
<td>④</td>
<td style="text-align: center;"><span class="math inline">3 × 3</span>
MaxPooling → <span class="math inline">1 × 1</span> 卷积</td>
<td style="text-align: center;">聚合背景信息、补充稳定性</td>
</tr>
</tbody>
</table>
<p>最后这<code>4</code>条分支输出在 通道维度上拼接成整体输出。</p>
<p><img src="/2025/11/08/Computer%20Vision/4.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/5.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/6.png"></p>
<p>1.进行<code>multiple convolution</code>时，若尺寸不匹配会进行<code>padding</code>，方便最后对输出进行拼接。</p>
<p>2.网络太深了会出现梯度消失问题。为此在中间层插入了两个辅助分类头，帮助梯度反传。</p>
<h3 id="resnet">ResNet</h3>
<p>当网络更深，损失函数下降趋于平缓时更难优化，因此<code>ResNet</code>提出了残差的概念。假设我们想让若干层网络拟合目标函数<span class="math inline"><em>H</em>(<em>x</em>)</span>，传统做法是让堆叠的卷积层直接学<span class="math inline"><em>H</em>(<em>x</em>)</span>，而<code>ResNet</code>提出：不直接学<span class="math inline"><em>H</em>(<em>x</em>)</span>，而是学「残差函数」<span class="math inline"><em>F</em>(<em>x</em>) = <em>H</em>(<em>x</em>) − <em>x</em></span>，于是输出为<span class="math inline"><em>H</em>(<em>x</em>) = <em>F</em>(<em>x</em>) + <em>x</em></span>。也就是说，这些卷积层不需要从零学到整个映射，只需学出相对于输入的微调。反向传播时，梯度可以直接沿着旁路流回前层，从而缓解梯度消失问题。
<span class="math display">$$
\frac{\partial L}{\partial x} = \frac{\partial L}{\partial y}(1 +
\frac{\partial F}{\partial x})
$$</span> 因为恒等项<code>1</code>存在，即使 <span class="math inline">$\frac{\partial F}{\partial x}$</span>
很小，梯度也不会完全消失。</p>
<p><img src="/2025/11/08/Computer%20Vision/7.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/8.png"></p>
<p>至于改进，我们会采用更宽的残差块，也就是增加卷积核的数量，或者像<code>ResNeXt</code>将残差块设置为多分支，原理是一样的。也可以用正则化的思路，引入随机深度，跳过一些残差块。</p>
<p><img src="/2025/11/08/Computer%20Vision/10.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/11.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/12.png"></p>
<h3 id="fractalnet">FractalNet</h3>
<p>提出了分形结构<span class="math inline"><em>f</em><sub><em>c</em> + 1</sub>(<em>x</em>) = <em>f</em><sub><em>c</em></sub>(<em>f</em><sub><em>c</em></sub>(<em>x</em>)) + <em>f</em><sub><em>c</em></sub>(<em>x</em>)</span>，不用残差而自然形成多层路径长度。</p>
<p><img src="/2025/11/08/Computer%20Vision/13.png"></p>
<h3 id="densenet">DenseNet</h3>
<p>既然残差是相邻层的加法连接，那如果我们让所有层都互相连接，信息会不会更充分？从而提出了<code>Dense Block</code>，各层相互连接。<span class="math inline"><em>x</em><sub><em>l</em></sub> = <em>H</em><sub><em>l</em></sub>([<em>x</em><sub>0</sub>, <em>x</em><sub>1</sub>, ..., <em>x</em><sub><em>l</em> − 1</sub>])</span>，也就是说，第
<span class="math inline"><em>l</em></span>
层的输入是所有前面层特征的拼接。<img src="/2025/11/08/Computer%20Vision/14.png"></p>
<h3 id="squeezenet">SqueezeNet</h3>
<p>提出了<code>fire module</code>。<code>Squeeze</code>层用<code>1×1</code>卷积先把输入通道压缩（减少进入<code>3×3</code>的计算量，类似<code>bottleneck</code>），<code>Expand</code>层再用<code>1×1</code>和<code>3×3</code>卷积提取特征，<code>1×1</code>用于局部线性变换，<code>3×3</code>提取空间上下文。<code>Concat</code>输出把两种卷积的结果拼接起来（融合不同感受野）。</p>
<p><img src="/2025/11/08/Computer%20Vision/15.png"></p>
<h2 id="rnn">RNN</h2>
<h3 id="principle">Principle</h3>
<p><code>RNN</code>即<code>Recurrent Neural Network</code>，循环神经网络。</p>
<p><code>RNN</code>主要处理的任务可以分为以下几类：1.<code>one to many</code>，比如把图像理解为一个句子
2.<code>many to one</code>，比如对视频进行分类
3.<code>many to many</code>，例如翻译。<code>RNN</code>本身就是处理可变序列数据的神经网络。</p>
<p><img src="/2025/11/08/Computer%20Vision/16.png"></p>
<p>核心公式：<span class="math inline"><em>h</em><sub><em>t</em></sub> = <em>f</em><sub><em>W</em></sub>(<em>h</em><sub><em>t</em> − 1</sub>, <em>x</em><sub><em>t</em></sub>)</span>。<span class="math inline"><em>h</em><sub><em>t</em></sub></span>为当前时刻的隐藏状态（<code>hidden state</code>），可以理解为网络在时刻
<span class="math inline"><em>t</em></span> 的“记忆”，<span class="math inline"><em>x</em><sub><em>t</em></sub></span>为当前时刻的输入（<code>input</code>），例如一个句子的第
<span class="math inline"><em>t</em></span> 个词向量，<span class="math inline"><em>h</em><sub><em>t</em> − 1</sub></span>上一个时刻的隐藏状态，携带历史信息，<span class="math inline"><em>f</em><sub><em>W</em></sub>(⋅)</span>带有参数
<span class="math inline"><em>W</em></span>
的非线性变换函数，定义了如何将“过去的信息”和“当前输入”融合成新的状态。</p>
<p><img src="/2025/11/08/Computer%20Vision/17.png"></p>
<p>本质上是用相同的权重矩阵<span class="math inline"><em>W</em></span>，在每个时步通过旧状态和新输入更新出新状态。在<code>one to many</code>/<code>many to one</code>/<code>many to many</code>任务中的主要区别就是输入是否需要在每个时步中加入。</p>
<p><img src="/2025/11/08/Computer%20Vision/18.png"></p>
<p>由于<code>RNN</code>具有可以捕捉序列的特性，最早被用于处理生成式模型的任务。每个时步内，隐藏层输出<span class="math inline"><em>h</em>(<em>t</em>) = <em>t</em><em>a</em><em>n</em><em>h</em>(<em>W</em><sub><em>h</em><em>h</em></sub><em>h</em><sub><em>t</em> − 1</sub> + <em>W</em><sub><em>x</em><em>h</em></sub><em>x</em><sub><em>t</em></sub>)</span>，即基于输入向量和旧状态得到新输出，经过<code>Softmax</code>激活后概率最高的字母不仅会作为输出，也会作为下一个时步的新输入向量。</p>
<p><img src="/2025/11/08/Computer%20Vision/19.png"></p>
<p>损失函数也在每个时步中叠加，而在计算损失函数时我们往往会选取片段时步的<code>loss</code>。</p>
<p><img src="/2025/11/08/Computer%20Vision/20.png"></p>
<p>但训练<code>RNN</code>只是对后面出现的字母进行了预测，很难捕捉到和前面所有时步的关系，这也是后来为什么<code>transformer</code>捕捉到的<code>attention</code>横空出世改变了<code>NLP</code>领域。在图像理解任务中，我们也会用到<code>RNN</code>网络，比如下面<code>one to many</code>的例子。这个方法效果不佳，因为它没有捕捉到文本信息和对应图像块的联系。因此，我们引入了<code>attention</code>来捕捉这种联系，我们的输入修改为图像某一个区域的<code>CNN</code>结果，而每一个图像块有其对应的文本。</p>
<p><img src="/2025/11/08/Computer%20Vision/21.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/22.png"></p>
<p>当然，<code>RNN</code>也是可以有多个隐藏层的，我们知道适当的增加网络深度可以提升性能。</p>
<p><img src="/2025/11/08/Computer%20Vision/23.png"></p>
<h3 id="lstm">LSTM</h3>
<p>在计算反向传播时，从尾部传到头部会乘上非常多的相同矩阵权重因子，因子过大会出现梯度爆炸的问题，过小会出现梯度消失的问题，为了解决反向传播的梯度问题，<code>LSTM</code>方法被提出。</p>
<p><img src="/2025/11/08/Computer%20Vision/24.png"></p>
<p><code>LSTM</code>把每个时步的细胞拆成四个门：<code>f</code>遗忘门，<code>i</code>输入门，<code>g</code>状态门，<code>o</code>输出门。
接收三个输入：上一个时间步的隐藏状态<span class="math inline"><em>h</em><sub><em>t</em> − 1</sub></span>，上一个时间步的细胞状态<span class="math inline"><em>C</em><sub><em>t</em> − 1</sub></span>，当前时间步的输入<span class="math inline"><em>x</em><sub><em>t</em></sub></span>。产生两个输出：当前时间步的隐藏状态<span class="math inline"><em>h</em><sub><em>t</em></sub></span>，当前时间步的细胞状态<span class="math inline"><em>C</em><sub><em>t</em></sub></span>。其内部通过精巧的“门”结构来调控信息的流动，一个门是一个由<code>Sigmoid</code>函数和点乘运算组成的结构。</p>
<p>遗忘门决定要从上一个细胞状态 <span class="math inline"><em>C</em><sub><em>t</em> − 1</sub></span>中遗忘哪些信息，输入<span class="math inline"><em>h</em><sub><em>t</em> − 1</sub></span>和 <span class="math inline"><em>x</em><sub><em>t</em></sub></span>并将二者拼接后，通过一个<code>Sigmoid</code>函数，产生一个在<code>[0, 1]</code>之间的向量
<span class="math inline"><em>f</em><sub><em>t</em></sub></span>，<span class="math inline"><em>f</em><sub><em>t</em></sub></span> 会与 <span class="math inline"><em>C</em><sub><em>t</em> − 1</sub></span>
进行点乘。如果 <span class="math inline"><em>C</em><sub><em>t</em> − 1</sub></span>
中的某个位置对应的 <span class="math inline"><em>f</em><sub><em>t</em></sub></span>
是<code>0</code>，那么该信息就会被遗忘；如果是<code>1</code>，则该信息会被完整保留。</p>
<p>输入门决定要在当前细胞状态中添加哪些新信息，<span class="math inline"><em>i</em><sub><em>t</em></sub></span>为<code>[0,1]</code>向量，<span class="math inline"><em>g</em><sub><em>t</em></sub></span>的取值被限制在<code>[-1,1]</code>。</p>
<p><span class="math inline"><em>i</em><sub><em>t</em></sub> = <em>σ</em>(<em>W</em><sub><em>i</em></sub> · [<em>h</em><sub><em>t</em> − 1</sub>, <em>x</em><sub><em>t</em></sub>] + <em>b</em><sub><em>i</em></sub>)</span></p>
<p><span class="math inline"><em>g</em><sub><em>t</em></sub> = <em>t</em><em>a</em><em>n</em><em>h</em>(<em>W</em><sub><em>g</em></sub> · [<em>h</em><sub><em>t</em> − 1</sub>, <em>x</em><sub><em>t</em></sub>] + <em>b</em><sub><em>g</em></sub>)</span></p>
<p>现在，我们将遗忘门和输入门的结果结合起来，更新细胞状态：<span class="math inline"><em>C</em><sub><em>t</em></sub> = <em>f</em><sub><em>t</em></sub> * <em>C</em><sub><em>t</em> − 1</sub> + <em>i</em><sub><em>t</em></sub> * <em>g</em><sub><em>t</em></sub></span>。这个公式是<code>LSTM</code>的灵魂所在，<span class="math inline"><em>f</em><sub><em>t</em></sub> * <em>C</em><sub><em>t</em> − 1</sub></span>决定丢弃多少旧信息，<span class="math inline"><em>i</em><sub><em>t</em></sub> * <em>g</em><sub><em>t</em></sub></span>：决定添加多少新信息，整个操作是线性的（只有加法和乘法），这一点对于反向传播至关重要。</p>
<p>输出门基于更新后的细胞状态，决定下一个隐藏状态<span class="math inline"><em>h</em><sub><em>t</em></sub></span>应该是什么。隐藏状态通常作为当前时间步的输出，并传递给下一个单元。</p>
<p><span class="math inline"><em>o</em><sub><em>t</em></sub> = <em>σ</em>(<em>W</em><sub><em>o</em></sub> · [<em>h</em><sub><em>t</em> − 1</sub>, <em>x</em><sub><em>t</em></sub>] + <em>b</em><sub><em>o</em></sub>)</span></p>
<p><span class="math inline"><em>h</em><sub><em>t</em></sub> = <em>o</em><sub><em>t</em></sub> * <em>t</em><em>a</em><em>n</em><em>h</em>(<em>C</em><sub><em>t</em></sub>)</span></p>
<p><img src="/2025/11/08/Computer%20Vision/25.png"></p>
<p><code>LSTM</code>是如何优化反向传播的呢？虽然它仍然保留了权重矩阵，但没有直接参与梯度更新的运算。核心在于细胞状态
<span class="math inline"><em>C</em><sub><em>t</em></sub></span>的更新路径。</p>
<p><span class="math inline"><em>C</em><sub><em>t</em></sub> = <em>f</em><sub><em>t</em></sub> * <em>C</em><sub><em>t</em> − 1</sub> + <em>i</em><sub><em>t</em></sub> * <em>g</em><sub><em>t</em></sub></span></p>
<p>在反向传播时，梯度需要从<span class="math inline"><em>C</em><sub><em>t</em></sub></span>流回<span class="math inline"><em>C</em><sub><em>t</em> − 1</sub></span>。根据链式法则，<span class="math inline"><em>C</em><sub><em>t</em></sub></span>对 <span class="math inline"><em>C</em><sub><em>t</em> − 1</sub></span>的偏导数是<span class="math inline"><em>f</em><sub><em>t</em></sub></span>（遗忘门的输出）。而<span class="math inline"><em>f</em><sub><em>t</em></sub></span>是一个由<code>Sigmoid</code>产生的，值在<code>[0, 1]</code>之间但不是恒为<code>0</code>或<code>1</code>的向量，从而避免了矩阵乘法的问题。</p>
<p><img src="/2025/11/08/Computer%20Vision/26.png"></p>
<h3 id="vit">VIT</h3>
<p><code>VIT</code>即<code>Visual Transformer</code>，是<code>Transformer</code>在视觉领域的应用。</p>
<h2 id="detection">Detection</h2>
<p>除了分类出小猫，我们也想知道：猫在哪里？能不能框出来？</p>
<p>首先我们阐释一下<code>localization</code>（定位）和<code>detection</code>（识别）的区别。<code>localization</code>是我知道这张图片是猫，要找到猫在哪里；而<code>detection</code>需要在给定的图片中识别出是否存在猫（有可能存在多个物体），如果有猫找到在哪里。可以说，<code>localization</code>是<code>detection</code>的简化。</p>
<p>我们先说说定位任务。把这个问题视为<code>regression</code>，数据集标注好图像的标签以及框的坐标<span class="math inline">(<em>x</em>, <em>y</em>, <em>w</em>, <em>h</em>)</span>，<span class="math inline">(<em>x</em>, <em>y</em>)</span>是边界框中心点相对于当前网格单元左上角的偏移量，值域<code>[0,1]</code>；<span class="math inline">(<em>w</em>, <em>h</em>)</span>是边界框的宽度和高度相对于整个图片的比例，值域<code>[0,1]</code>。图像经过<code>CNN</code>处理后，定义两个损失函数：分类的损失和位置的损失，本质上是<code>multi-task loss</code>，对两个损失函数进行加权求和，超参数的设置往往需要实验。类似方式的还有姿态估计，对每个关节点的位置<span class="math inline">(<em>x</em>, <em>y</em>)</span>进行标注，损失由每个部位的<code>L2 Loss</code>相加。</p>
<p><img src="/2025/11/08/Computer%20Vision/27.png"></p>
<p>识别任务相较定位任务更加复杂，因为它不知道图像里是否确切有某个物体，接下来介绍几个方法。</p>
<h3 id="sliding-window">Sliding Window</h3>
<p>把图像切成块，用滑动窗口在不同图像块平移，将每个窗口识别为某个目标或背景，从而识别出目标。这种方法计算成本昂贵，因为每滑动一次就要用一次<code>CNN</code>。</p>
<p><img src="/2025/11/08/Computer%20Vision/28.png"></p>
<h3 id="r-cnn">R-CNN</h3>
<p>先提出<code>Region Proposals</code>的概念，我们通过区域选择网络选取图像中可能出现物体的区域，相对<code>Sliding Window</code>减少了无效背景的干扰，但是仍然会有很多噪声。</p>
<p><code>R-CNN</code>提出了<code>Regions of Interest(RoI)方法</code>，先寻找可能含目标的图像块对感兴趣的区域进行处理，调整为固定尺寸
<code>CNN</code>处理后用<code>SVM</code>对区域进行分类。但是有很多问题，比如，选择模型没法根据具体情况进行训练，而且每次输入框尺寸不一样，<code>CNN</code>要反复跑，训练速度不佳。</p>
<p><img src="/2025/11/08/Computer%20Vision/29.png"></p>
<h3 id="faster-r-cnn">Faster R-CNN</h3>
<p>在<code>R-CNN</code>基础上改进得到了<code>Faster R-CNN</code>。先只跑一次卷积得到<code>feature map</code>并选取感兴趣区域，经过
<code>RoI Pooling</code>将尺寸固定后通过共享的全连接层进行分类与边界的训练。</p>
<p><img src="/2025/11/08/Computer%20Vision/30.png"></p>
<h3 id="yolo">YOLO</h3>
<p>但最知名的<code>YOLO</code>算法并没有采用选择感兴趣区域的方法，这里我们简要讲解一下<code>YOLOv1</code>的原理。其核心是把图像切成网格（如<code>7*7</code>），并且预测某类目标出现在框中的概率有多大，输出<span class="math inline">7 * 7 * (5 * <em>B</em> + <em>C</em>)</span>。而框的选取是围绕每一个网格的中心点取<span class="math inline"><em>B</em></span>个一定大小的<code>box</code>，每个<code>box</code>有五个参数。<span class="math inline">(<em>x</em>, <em>y</em>, <em>w</em>, <em>h</em>)</span>描述边界框的位置和大小，<code>confidence</code>（置信度）表示这个框内包含一个目标的可能性有多大，以及这个框的位置预测得准不准。<span class="math inline"><em>C</em></span>代表数据集中所有待检测的类别总数，输出包括每个类别的评分。对于每个网格单元，它只预测一组类别概率，记作
<span class="math inline"><em>P</em>(<em>C</em><em>l</em><em>a</em><em>s</em><em>s</em><sub><em>i</em></sub>|<em>O</em><em>b</em><em>j</em><em>e</em><em>c</em><em>t</em>)</span>，即“如果这个网格里有物体，那么这个物体属于第<code>i</code>个类的概率是多少”。训练时，损失包括有目标的框坐标回归误差；置信度误差加权（有目标
vs 无目标）；类别预测误差。</p>
<p><img src="/2025/11/08/Computer%20Vision/31.png"></p>
<p>除此之外，我们还可以延伸到识别加标注的任务<code>Dense Captioning</code>，框出区域并且附以文字说明，接下来的操作和识别任务类似，只不过最后用<code>RNN</code>对候选框进行预测文字说明，这也是多模态模型的早期形态。</p>
<p><img src="/2025/11/08/Computer%20Vision/32.png"></p>
<h2 id="segmentation">Segmentation</h2>
<p>分割任务是识别任务的延伸，在识别出物体的基础上分割出轮廓。</p>
<h3 id="mask-r-cnn">Mask R-CNN</h3>
<p>其核心可概括为<code>Faster R-CNN</code> +
一个并行的掩码预测分支。它为每个检测到的物体预测一个二值的掩码，精确勾勒出物体的像素级轮廓。损失函数加上像素级的轮廓掩码预测：<span class="math inline">$L_{\text{mask}} = -\frac{1}{m^2} \sum_{i,j} \left[
y_{ij} \log M_{ij}^k + (1 - y_{ij}) \log (1 - M_{ij}^k)
\right]$</span></p>
<p>这个思路在姿态估计上同样有效，需要添加一个关节点坐标分支。</p>
<p><img src="/2025/11/08/Computer%20Vision/33.png"></p>
<h3 id="semantic-segmentation">Semantic Segmentation</h3>
<p>每个像素都有标签标注，但存在问题：两个牛重叠在一起，像素标签相同，无法区分。改进方法是滑动窗口<code>sliding window</code>，用图像块代替像素，但是计算成本高。<code>fully convolutional</code>的改进是采用<code>downsampling</code>和<code>upsampling</code>结合的网络。由于<code>maxpooling</code>有去噪效果，但分割需要明显的区分，我们采用<code>unpooling</code>对像素进行重复与填充增加边界处的噪声，也就是<code>upsampling</code>的过程。</p>
<p><img src="/2025/11/08/Computer%20Vision/34.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/35.png"></p>
<p>我们可以引申到<code>transpose convolution</code>的概念，类似于卷积的逆运算，其本质便是<code>upsampling</code>。我们用<code>0</code>对每个元素行列之间进行填充使之变成稀疏矩阵，随后进行步长为<code>1</code>的普通卷积，最终得到的特征图就是输入像素的特征印记在该位置叠加的结果。那为什么叫转置（<code>transpose</code>）卷积呢？为了实现尺寸上的逆向，它使用普通卷积矩阵
<span class="math inline"><em>C</em></span>的转置 <span class="math inline"><em>C</em><sup><em>T</em></sup></span>，乘以被展平的输入向量
<span class="math inline"><em>x</em></span>，得到一个更大的输出向量
<span class="math inline"><em>o</em><sup>′</sup></span>。即<span class="math inline"><em>o</em><sup>′</sup> = <em>C</em><sup><em>T</em></sup><em>x</em></span>。</p>
<p><img src="/2025/11/08/Computer%20Vision/36.png"></p>
<h3 id="u-net">U-Net</h3>
<h2 id="visualizing">Visualizing</h2>
<p>机器学习的一大问题就是黑箱，而可视化能让我们提升视觉任务的可解释性，也能在实验中更了解每一步的情况。除此之外，通过对中间特征的捕捉我们可以完成一些风格转换任务。</p>
<h3 id="first-layer">First Layer</h3>
<p>卷积神经网络的第一层往往是卷积层，观察每个卷积核的输出我们可以初步观察图像的特征。</p>
<p><img src="/2025/11/08/Computer%20Vision/37.png"></p>
<h3 id="filterskernels">Filters/Kernels</h3>
<p>低层卷积核可以直接可视化，因为它们学到的是图像的基本特征（如边缘、颜色、纹理）；高层卷积核虽然也能画出来，但往往看不出明显的可解释模式。</p>
<p><img src="/2025/11/08/Computer%20Vision/38.png"></p>
<h3 id="last-layer">Last Layer</h3>
<p>最后一层往往输出得分，但对一些复杂的输出我们需要<code>dimensionality reduction</code>。如，常见的<code>PCA</code>主成分分析。<code>t-SNE</code>也是一种降维方法。</p>
<p><img src="/2025/11/08/Computer%20Vision/39.png"></p>
<h3 id="activations">Activations</h3>
<p><code>feature map</code>可以看到这层网络关注到了什么特征。</p>
<p><code>maximally activating patches</code>可以看到最强烈激活某个卷积核的图像片段。</p>
<p><img src="/2025/11/08/Computer%20Vision/40.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/41.png"></p>
<h3 id="occlusion-experiments">Occlusion Experiments</h3>
<p>通过遮挡图像并绘制<code>CNN</code>热力图，可以确认某块图像的重要性。</p>
<p><span class="math inline"><em>S</em>(<em>x</em>, <em>y</em>) = <em>p</em><sub><em>o</em><em>r</em><em>i</em><em>g</em></sub> − <em>p</em><sub><em>o</em><em>c</em><em>c</em><em>l</em><em>u</em><em>d</em><em>e</em><em>d</em></sub>(<em>x</em>, <em>y</em>)</span></p>
<p>其中：<span class="math inline"><em>p</em><sub>orig</sub></span>表示原图预测的类别概率；<span class="math inline"><em>p</em><sub>occluded(<em>x</em>, <em>y</em>)</sub></span>表示遮挡
<span class="math inline">(<em>x</em>, <em>y</em>)</span>
区域后的类别概率；<span class="math inline"><em>S</em>(<em>x</em>, <em>y</em>)</span>表示该区域对模型预测的重要性（值越大说明越关键）。</p>
<p><img src="/2025/11/08/Computer%20Vision/42.png"></p>
<h3 id="saliency-maps">Saliency Maps</h3>
<p>对像素进行扰动计算对分类分值的影响。往往会和<code>grabcut</code>混合使用，但缺乏监督。</p>
<p><span class="math inline">$\text{Saliency}(x, y) = \left|
\frac{\partial y_c}{\partial x_{ij}} \right|$</span></p>
<p><img src="/2025/11/08/Computer%20Vision/43.png"></p>
<h3 id="intermediate-features-via-guided-backprop">Intermediate Features
Via (Guided) Backprop</h3>
<p>引导式反向传播，在标准反向传播中，梯度传播方式为<span class="math inline"><em>δ</em><sub><em>l</em></sub> = <em>δ</em><sub><em>l</em> + 1</sub> ⋅ <em>f</em><sup>′</sup>(<em>z</em><sub><em>l</em></sub>)</span>，其中
<span class="math inline"><em>f</em><sup>′</sup>(<em>z</em><sub><em>l</em></sub>)</span>
是<code>ReLU</code>的导数。若前向时 <span class="math inline"><em>z</em><sub><em>l</em></sub> &lt; 0</span>（<code>ReLU</code>输出为<code>0</code>），梯度被阻断；若上层梯度
<span class="math inline"><em>δ</em><sub><em>l</em> + 1</sub></span>
为负，仍可能产生负向信号。</p>
<p><code>Guided Backprop</code>进行了改进，只保留正向贡献： <span class="math display">$$
\delta_l =
\begin{cases}
\delta_{l+1}, &amp; \text{if } \delta_{l+1} &gt; 0 \text{ and } z_l &gt;
0 \\
0, &amp; \text{otherwise}
\end{cases}
$$</span></p>
<p>也就是：不让负梯度传播回来且不让前向激活为负的神经元贡献梯度。</p>
<p><img src="/2025/11/08/Computer%20Vision/44.png"></p>
<h3 id="cnn-features">CNN features</h3>
<p><code>Gradient Ascent</code>用于优化图像特征的可视化，<span class="math inline"><em>f</em>(<em>I</em>)</span>表示神经元对输入图像
<span class="math inline"><em>I</em></span> 的激活值，<span class="math inline"><em>R</em>(<em>I</em>)</span>是正则项，保证图像自然、不发散，可表示为<span class="math inline"><em>I</em><sup>*</sup> = <em>a</em><em>r</em><em>g</em><em>m</em><em>a</em><em>x</em><sub><em>I</em></sub>[<em>f</em>(<em>I</em>) + <em>R</em>(<em>I</em>)]</span>。</p>
<p><img src="/2025/11/08/Computer%20Vision/45.png"></p>
<p>另一种表达是<span class="math inline"><em>I</em><sup>*</sup> = <em>a</em><em>r</em><em>g</em><em>m</em><em>a</em><em>x</em>[<em>S</em><sub><em>c</em></sub>(<em>I</em>) − <em>λ</em>||<em>I</em>||<sub>2</sub><sup>2</sup>]</span>
，<span class="math inline"><em>S</em><sub><em>c</em></sub>(<em>I</em>)</span>表示类别
<span class="math inline"><em>c</em></span> 的得分，<span class="math inline">|<em>I</em>|<sub>2</sub><sup>2</sup></span>表示图像像素的
L2 范数正则项，<span class="math inline"><em>λ</em></span>表示正则项权重。也就是找到一张图
<span class="math inline"><em>I</em><sup>*</sup></span>，能最大程度地激活类别
<span class="math inline"><em>c</em></span>
的神经元，同时又保持图像看起来合理。</p>
<p><img src="/2025/11/08/Computer%20Vision/46.png"></p>
<p>但是一般的正则化可能引入过多噪声，我们选用更平滑的方案<code>Gaussian Blur</code>/<code>clip pixels with small values to 0</code>/<code>clip pixels with small gradients to 0</code>。</p>
<p><img src="/2025/11/08/Computer%20Vision/47.png"></p>
<h3 id="fooling-imagesadversial-examples">Fooling images/Adversial
Examples</h3>
<p>用错误的标签混淆，对比视觉任务中的差异，类似于
<code>GAN</code>的想法。</p>
<p><img src="/2025/11/08/Computer%20Vision/48.png"></p>
<h3 id="deep-dreamingamplify-existing-features">Deep Dreaming：Amplify
Existing Features</h3>
<p>通过网络放大检测到的特征，可以应用到风格迁移。</p>
<p><img src="/2025/11/08/Computer%20Vision/49.png"></p>
<h3 id="feature-inversion">Feature Inversion</h3>
<p>通过最小化以下目标函数，从特征向量中“反解”出一张图像：</p>
<p><span class="math display">∥<em>Φ</em>(<em>x</em>) − <em>Φ</em><sub>0</sub>∥<sup>2</sup> + <em>λ</em><em>R</em>(<em>x</em>)</span></p>
<p>其中，<span class="math inline"><em>Φ</em>(<em>x</em>)</span>：当前图像在<code>CNN</code>某层的特征；<span class="math inline"><em>Φ</em><sub>0</sub></span>：目标特征向量（来自原图像）；<span class="math inline"><em>R</em>(<em>x</em>)</span>：正则化项，保持图像平滑自然；<span class="math inline"><em>λ</em></span>：权重系数，用于平衡特征匹配与图像自然度。通过优化该式，可以重建出在特征空间上与原图匹配的图像，从而揭示<code>CNN</code>不同层捕捉到的特征信息及其损失情况。</p>
<p><img src="/2025/11/08/Computer%20Vision/50.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/51.png"></p>
<h3 id="texture-synthesis">Texture Synthesis</h3>
<p>通过<code>Nearest Neighbour</code>进行邻近像素的合成。</p>
<p><img src="/2025/11/08/Computer%20Vision/52.png"></p>
<h3 id="neural-texture-synthesis">Neural Texture Synthesis</h3>
<p>神经纹理合成通过<code>Gram Matrix</code>实现。先输入纹理图像，通过预训练<code>CNN</code>得到每层特征图<span class="math inline"><em>F</em><sup><em>l</em></sup> ∈ ℝ<sup><em>C</em><sub><em>l</em></sub> × <em>H</em><sub><em>l</em></sub> × <em>W</em><sub><em>l</em></sub></sup></span>，随后计算<code>Gram</code>矩阵（特征通道间的共现统计）<span class="math inline"><em>G</em><sup><em>l</em></sup> = <em>F</em><sup><em>l</em></sup>(<em>F</em><sup><em>l</em></sup>)<sup><em>T</em></sup></span>，其中
<span class="math inline"><em>G</em><sup><em>l</em></sup></span> 尺寸为
<span class="math inline"><em>C</em><sub><em>l</em></sub> × <em>C</em><sub><em>l</em></sub></span>，表示不同特征的相关性。</p>
<p>然后，随机初始化图像 <span class="math inline"><em>x</em></span>，并让其<code>Gram</code>矩阵与目标图匹配：<span class="math inline"><em>x</em><sup>*</sup> = arg min<sub><em>x</em></sub>∑<sub><em>l</em></sub><em>w</em><sub><em>l</em></sub>∥<em>G</em><sup><em>l</em></sup>(<em>x</em>) − <em>G</em><sup><em>l</em></sup>(<em>I</em><sub>style</sub>)∥<sup>2</sup></span></p>
<p>最后通过反向传播更新 <span class="math inline"><em>x</em></span>，逐步优化生成结果。</p>
<p><img src="/2025/11/08/Computer%20Vision/53.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/54.png"></p>
<h3 id="nueral-style-transfer">Nueral Style Transfer</h3>
<p>输入有<code>content image</code> + <code>style image</code> +
<code>output image</code>（从<code>noise</code>开始优化），随后我们通过<code>CNN</code>特征提取并用<code>Gram</code>进行风格转换，损失函数包括内容损失和风格损失，损失函数权重的改变会导致内容和风格的倾向。
<span class="math display">$$
\mathcal{L}_{\text{content}} = \frac{1}{2}\|\Phi^l(\hat{y}) -
\Phi^l(y_c)\|^2 \\ \mathcal{L}_{\text{style}} = \sum_l w_l
\|G^l(\hat{y}) - G^l(y_s)\|^2
$$</span></p>
<p><img src="/2025/11/08/Computer%20Vision/55.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/56.png"></p>
<p>但原始方法每生成一张图都要从随机噪声开始反复迭代优化，计算量极大、无法实时使用。<code>Fast Style Transfer</code>
的关键改进是：训练一个前馈网络（<code>Feedforward Network</code>）来“学会”这种优化过程。训练阶段用预训练<code>CNN</code>计算内容损失与风格损失，监督前馈网络学习生成风格化图像，推理阶段只需一次前向传播即可完成风格迁移，速度快到可以实时应用。</p>
<p><img src="/2025/11/08/Computer%20Vision/57.png"></p>
<p>通过<code>Conditional Instance Normalization (CIN)</code>，让一个网络能够处理多种艺术风格，而无需为每种风格单独训练模型。在标准实例归一化中<span class="math inline">$x_{\text{norm}} = \frac{x - \mu}{\sigma}, \quad z =
\gamma x_{\text{norm}} +
\beta$</span>，在<code>CIN</code>中每种风格都有独立的参数 <span class="math inline">(<em>γ</em><sub><em>s</em></sub>, <em>β</em><sub><em>s</em></sub>)</span>；卷积层共享，但根据风格标签选择不同的缩放与偏移；训练时随机切换风格，学习多风格映射。</p>
<p><img src="/2025/11/08/Computer%20Vision/58.png"></p>
<h2 id="generative-models">Generative Models</h2>
<p>生成任务需要从给定的训练数据中学习到生成新样本的方法，是无监督学习任务。生成方法我们可以归为<code>explicit density estimation</code>（显式密度估计）和<code>implicit density estimation</code>（隐式密度估计）两类。下面的<code>Pixel RNNS and CNNS</code>/<code>VAE</code>属于显式，<code>GAN</code>属于隐式。</p>
<p><img src="/2025/11/08/Computer%20Vision/59.png"></p>
<h3 id="pixel-rnns-and-cnns">Pixel RNNs and CNNs</h3>
<p>图像生成被拆分为像素序列，每个像素的分布由前面像素条件决定。 <span class="math inline">$p_{\theta}(x) =
\prod_{i=1}^{n}p_{\theta}(x_i|x_1,...,x_{i-1})$</span></p>
<p>目标是最大化训练集似然<span class="math inline">max<sub><em>θ</em></sub>∑<sub><em>x</em></sub>∑<sub><em>i</em></sub>log <em>p</em><sub><em>θ</em></sub>(<em>x</em><sub><em>i</em></sub>|<em>x</em><sub>1</sub>, ..., <em>x</em><sub><em>i</em> − 1</sub>)</span>，等价于最小化交叉熵损失，即比较模型输出的像素分布与真实像素，让真实像素获得更高概率，从而学习到整个图像分布。往往使用链式法则通过一维分布求解最大化似然，并用神经网络表述概率分布。</p>
<p><code>RNN</code>建模像素间依赖，在先前像素的基础上对拐角的像素进行预测，但是逐序列生成太慢了。</p>
<p><img src="/2025/11/08/Computer%20Vision/60.png"></p>
<p><code>CNN</code>同样自回归建模，但用<code>masked convolution</code>代替<code>RNN</code>。卷积核仅访问已生成像素（上方、左方），避免信息泄漏。<code>CNN</code>比<code>RNN</code>快，因为训练阶段可并行（整图卷积）。</p>
<p><img src="/2025/11/08/Computer%20Vision/61.png"></p>
<h3 id="vaevariational-autoencoders">VAE(Variational Autoencoders)</h3>
<p>我们先说说<code>Autoencoder</code>。自编码器由两部分组成：<code>Encoder</code>（编码器）将输入数据<span class="math inline"><em>x</em></span>压缩为低维特征表示<span class="math inline"><em>z</em> = <em>f</em><sub>enc</sub>(<em>x</em>)</span>；<code>Decoder</code>（解码器）从特征<span class="math inline"><em>z</em></span>重建出原始输入<span class="math inline"><em>x̂</em> = <em>f</em><sub>dec</sub>(<em>z</em>)</span>。通过最小化重建误差，使输出尽量接近输入：<span class="math inline">ℒ = ∥<em>x</em> − <em>x̂</em>∥<sub>2</sub><sup>2</sup></span>。</p>
<p><img src="/2025/11/08/Computer%20Vision/62.png"></p>
<p>变分自编码器在自编码器的基础上，引入概率分布建模和变分推断，目标是学习一个潜在空间分布，使得从该空间采样也能生成与训练数据相似的样本，从而实现真正的生成模型。</p>
<p>生成过程中，<span class="math inline"><em>z</em> ∼ <em>p</em><sub><em>θ</em></sub>(<em>z</em>),  <em>x</em> ∼ <em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>，其中<span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>z</em>)</span>为潜在变量的先验分布（通常为标准正态分布），<span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>为解码器生成图像的条件分布，整个观测样本<span class="math inline"><em>x</em></span>的概率为<span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>) = ∫<em>p</em><sub><em>θ</em></sub>(<em>z</em>)<em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)<em>d</em><em>z</em></span>。</p>
<p><code>Encoder</code>输出潜变量的均值与方差<span class="math inline"><em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em>) = 𝒩(<em>μ</em><sub><em>z</em>|<em>x</em></sub>, <em>Σ</em><sub><em>z</em>|<em>x</em></sub>)</span>，<code>Decoder</code>根据采样的<span class="math inline"><em>z</em></span>生成重建图像<span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)</span>。由于真实后验<span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>z</em>|<em>x</em>)</span>无法直接求解，引入近似分布<span class="math inline"><em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em>)</span>来替代它，这一步称为变分推断。</p>
<p><img src="/2025/11/08/Computer%20Vision/63.png"></p>
<p>通过推导得到似然下界： <span class="math display">log <em>p</em><sub><em>θ</em></sub>(<em>x</em>) ≥ 𝔼<sub><em>z</em> ∼ <em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em>)</sub>[log <em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)] − <em>D</em><sub><em>K</em><em>L</em></sub>(<em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em>) || <em>p</em><sub><em>θ</em></sub>(<em>z</em>))</span>
其中，重建项最大化输入数据的重建似然，使生成结果接近原图；<code>KL</code>散度项约束编码器输出分布接近标准正态先验，使潜在空间连续且可采样。</p>
<p><img src="/2025/11/08/Computer%20Vision/64.png"></p>
<p>由于积分形式的边缘似然<span class="math inline"><em>p</em><sub><em>θ</em></sub>(<em>x</em>) = ∫<em>p</em><sub><em>θ</em></sub>(<em>z</em>)<em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)<em>d</em><em>z</em></span>无法直接优化，因此通过从<span class="math inline"><em>x</em></span>编码到潜变量<span class="math inline"><em>z</em></span>，再从<span class="math inline"><em>z</em></span>解码回<span class="math inline"><em>x</em></span>​时引入高斯分布以增加随机性，用均值和协方差对潜在空间进行建模：<span class="math inline"><em>z</em> = <em>μ</em><sub><em>z</em>|<em>x</em></sub> + <em>Σ</em><sub><em>z</em>|<em>x</em></sub><sup>1/2</sup> ⋅ <em>ϵ</em>,  <em>ϵ</em> ∼ 𝒩(0, <em>I</em>)</span></p>
<p>这样可将随机性从网络参数中分离，使得整个过程能够反向传播。最终的优化目标为：<span class="math inline">ℒ(<em>x</em>; <em>θ</em>, <em>ϕ</em>) = 𝔼 * <em>z</em> ∼ <em>q</em> * <em>ϕ</em>(<em>z</em>|<em>x</em>)[log <em>p</em><sub><em>θ</em></sub>(<em>x</em>|<em>z</em>)] − <em>D</em><sub><em>K</em><em>L</em></sub>(<em>q</em><sub><em>ϕ</em></sub>(<em>z</em>|<em>x</em>), ||,<em>p</em><sub><em>θ</em></sub>(<em>z</em>))</span></p>
<p>训练时通过三步完成：首先前向传播完成“编码 → 采样 →
解码”，然后计算重建误差与<code>KL</code>散度，最后反向传播以联合优化编码器与解码器参数<span class="math inline">(<em>θ</em>, <em>ϕ</em>)</span>。</p>
<p><img src="/2025/11/08/Computer%20Vision/65.png"></p>
<h3 id="gangeneration-adversial-network">GAN(Generation Adversial
Network)</h3>
<p>生成对抗网络的本质依然是输入任意噪声经过网络输出图像。网络分为<code>Generator Network</code>和<code>Discriminator Network</code>。生成网络生成<code>fake images</code>，和<code>real images</code>对比训练<code>Discriminator</code>。</p>
<p><img src="/2025/11/08/Computer%20Vision/66.png"></p>
<p>目标函数是<code>minmax</code>函数博弈。</p>
<p><span class="math inline">min<sub><em>θ</em><sub><em>g</em></sub></sub>max<sub><em>θ</em><sub><em>d</em></sub></sub>[𝔼<sub><em>x</em> ∼ <em>p</em><sub>data</sub>(<em>x</em>)</sub>[log <em>D</em><sub><em>θ</em><sub><em>d</em></sub></sub>(<em>x</em>)] − 𝔼<sub><em>z</em> ∼ <em>p</em>(<em>z</em>)</sub>[log (1 − <em>D</em><sub><em>θ</em><sub><em>d</em></sub></sub>(<em>G</em><sub><em>θ</em><sub><em>g</em></sub></sub>(<em>z</em>)))]]</span></p>
<p>其中，<span class="math inline"><em>D</em><sub><em>θ</em><sub><em>d</em></sub></sub>(<em>x</em>)</span>：判别器对真实样本
<span class="math inline"><em>x</em></span>
输出为真的概率（<code>0–1</code>），<span class="math inline"><em>D</em><sub><em>θ</em><sub><em>d</em></sub></sub>(<em>G</em><sub><em>θ</em><sub><em>g</em></sub></sub>(<em>z</em>))</span>为判别器对生成样本
<span class="math inline"><em>G</em>(<em>z</em>)</span> 输出为真的概率
。判别器希望最大化该目标函数，使真伪样本区分得更好（对真实图像 <span class="math inline"><em>x</em></span>：输出 <span class="math inline"><em>D</em>(<em>x</em>) ≈ 1</span>；对生成图像 <span class="math inline"><em>G</em>(<em>z</em>)</span>：输出 <span class="math inline"><em>D</em>(<em>G</em>(<em>z</em>)) ≈ 0</span>）。判别器的训练相当于一个二分类问题，真实样本标记为<code>1</code>，生成样本标记为<code>0</code>。生成器希望最小化该目标函数，使得生成样本尽可能逼真。目标是让判别器认为生成图像也是真实的，即<span class="math inline"><em>D</em>(<em>G</em>(<em>z</em>)) ≈ 1</span>，生成器不断优化，使
<span class="math inline"><em>G</em>(<em>z</em>)</span>
更接近真实数据分布 <span class="math inline"><em>p</em><sub>data</sub>(<em>x</em>)</span>。</p>
<p>训练过程构成一个零和博弈：判别器最大化损失 <span class="math inline">⇒</span> 学会区分真假，生成器最小化损失 <span class="math inline">⇒</span> 欺骗判别器，当二者达到平衡时<span class="math inline"><em>p</em><sub><em>G</em></sub>(<em>x</em>) = <em>p</em><sub>data</sub>(<em>x</em>),  <em>D</em>(<em>x</em>) = 0.5</span>，判别器无法再区分真假样本。</p>
<p><img src="/2025/11/08/Computer%20Vision/67.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/70.png"></p>
<p>当判别器训练得很强时，<span class="math inline"><em>D</em>(<em>G</em>(<em>z</em>)) ≈ 0</span>，此时生成器的梯度
<span class="math inline">∇<sub><em>θ</em><sub><em>g</em></sub></sub>log (1 − <em>D</em>(<em>G</em>(<em>z</em>)))</span>
极小，导致生成器几乎无法更新，训练停滞。为增强梯度信号，提出改用以下目标，即不再最小化
<span class="math inline">log (1 − <em>D</em>(<em>G</em>(<em>z</em>)))</span>，而是最大化<span class="math inline">log <em>D</em>(<em>G</em>(<em>z</em>))</span>，这样即使生成样本较差，梯度仍保持较大，生成器能持续学习。</p>
<p><span class="math inline">max<sub><em>θ</em><sub><em>g</em></sub></sub>𝔼<sub><em>z</em> ∼ <em>p</em>(<em>z</em>)</sub>[log <em>D</em><sub><em>θ</em><sub><em>d</em></sub></sub>(<em>G</em><sub><em>θ</em><sub><em>g</em></sub></sub>(<em>z</em>))]</span></p>
<p><img src="/2025/11/08/Computer%20Vision/68.png"></p>
<p><img src="/2025/11/08/Computer%20Vision/69.png"></p>
<p><code>CNN</code>能更好地建模局部相关性与空间层次信息，相比全连接层，通过<code>Convolutional Architectures</code>能够帮助<code>Generator</code>生成更好的样本。</p>
<p><img src="/2025/11/08/Computer%20Vision/71.png"></p>
<p><code>GAN</code>有很多有意思的应用，比如<code>interpretable vector math</code>，通过向量的加减叠加实现视觉效果的合成。除此之外，<code>GAN</code>还被广泛用于风格转换等任务，从而衍生出了<code>GAN</code>家族。</p>
<p><img src="/2025/11/08/Computer%20Vision/72.png"></p>
<h3 id="diffusion">Diffusion</h3>
<h2 id="vlm">VLM</h2>
<p><code>CLIP</code></p>
<h2 id="附录1-training-details">附录1 Training Details</h2>
<p>无论是什么视觉任务，训练神经网络必然是绕不开的，我们来回顾一下训练的细节。</p>
<p><strong>Experiment</strong></p>
<p>实验是一个<code>babysitting</code>的过程，需要密切的关注全流程中各指标的变化情况。</p>
<p>最直观的就是通过<code>cross-validation</code>评估训练结果以及训练过程中<code>loss</code>的变化曲线（波动或者平缓），进而调整<code>lr(decay)</code>,<code>batch_size</code>,<code>regularization</code>等参数，达到最优效果。在选取新参数时，往往会采用<code>random search</code>/<code>grid search</code>的方法。不过，目前的<code>pytorch</code>已经集成好了这些功能。</p>
<p><strong>Fancier optimization</strong></p>
<p><code>SGD</code>
会出现“之”字形更新，核心原因在于其梯度的随机性。它使用单个或小批量样本的梯度来估计真实梯度，该估计带有噪声和高方差。当损失函数的等高线呈狭长山谷状时，这种带有噪声的更新方向会与指向全局最小值的理想路径产生剧烈偏差。为了解决这个问题，我们引入<code>Momentum</code>，在某个方向上赋予动量，使其不会停留在局部最小值点或鞍点，也抵消了噪声影响。</p>
<p><code>AdaGrad</code>通过累计梯度调整自适应学习率，在凸函数上效果较好；而<code>RMSProp</code>引入
<code>decay_rate</code>解决梯度减小过快的问题，二者结合得出了<code>Adam</code>。</p>
<pre class="language-python" data-language="python"><code class="language-python">first_moment <span class="token operator">=</span> <span class="token number">0</span>
second_moment <span class="token operator">=</span> <span class="token number">0</span>
<span class="token keyword">while</span> <span class="token boolean">True</span><span class="token punctuation">:</span>
    dx <span class="token operator">=</span> compute_gradient<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
    first_moment <span class="token operator">=</span> beta1 <span class="token operator">*</span> first_moment <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> beta1<span class="token punctuation">)</span> <span class="token operator">*</span> dx <span class="token comment"># Momentum</span>
    second_moment <span class="token operator">=</span> beta2 <span class="token operator">*</span> second_moment <span class="token operator">+</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> beta2<span class="token punctuation">)</span> <span class="token operator">*</span> dx <span class="token operator">*</span> dx <span class="token comment"># RMSProp</span>
    first_unbias <span class="token operator">=</span> first_moment <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> beta1 <span class="token operator">**</span> t<span class="token punctuation">)</span> <span class="token comment"># bias correction</span>
    second_unbias <span class="token operator">=</span> second_moment <span class="token operator">/</span> <span class="token punctuation">(</span><span class="token number">1</span> <span class="token operator">-</span> beta2 <span class="token operator">**</span> t<span class="token punctuation">)</span> <span class="token comment"># bias correction</span>
    x <span class="token operator">-=</span> learning_rate <span class="token operator">*</span> first_moment <span class="token operator">/</span> <span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>second_moment<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token number">1e-7</span><span class="token punctuation">)</span> <span class="token comment"># RMSProp</span></code></pre>
<p>如果<code>loss</code>以平滑的曲线下降，那么证明是合适的学习率。</p>
<p><strong>Loss</strong></p>
<p>我们回顾一下各大损失函数的特点。但一般来说，<code>ReLU</code>是最常用的。</p>
<ul>
<li><p><code>sigmoid</code>：值域<code>[0,1]</code>，但是存在梯度消失（<span class="math inline"><em>x</em></span>过大时斜率趋近于<code>0</code>)，<code>e</code>增加计算资源，激活函数输出不是以<code>0</code>为中心（恒为正，不同参数梯度方向全部相同）等问题。（有时预处理会用零均值化：<span class="math inline">$\hat{x_i}=x_i-\mu$</span>，改变数据分布近似以<code>0</code>为中心）</p></li>
<li><p><code>tanh</code>：值域<code>[-1,1]</code>，优化了<code>sigmoid</code>的输出问题，但是梯度消失无法解决。</p></li>
<li><p><code>(Leaky) ReLU</code>：<span class="math inline"><em>m</em><em>a</em><em>x</em>(0, <em>x</em>)</span>，虽然解决了梯度消失问题，但是<span class="math inline"><em>x</em> &lt; 0</span>时神经元会死亡。引入<code>Leaky ReLU</code>，在负数区域引入小斜率<span class="math inline"><em>α</em></span>，表达式为<span class="math inline"><em>m</em><em>a</em><em>x</em>(<em>α</em><em>x</em>, <em>x</em>)</span></p></li>
<li><p><code>ELU</code>：<span class="math inline"><em>x</em> &lt; 0</span>时<span class="math inline"><em>α</em>(<em>e</em><sup><em>x</em></sup> − 1)</span>，引入非线性关系，更鲁棒。</p></li>
<li><p><code>maxout</code>：<span class="math inline"><em>m</em><em>a</em><em>x</em>(<em>w</em><sub>1</sub><sup><em>T</em></sup><em>x</em> + <em>b</em><sub>1</sub>, <em>w</em><sub>2</sub><sup><em>T</em></sup><em>x</em> + <em>b</em><sub>2</sub>)</span>，但参数量翻倍，增加了计算资源。</p></li>
</ul>
<p><strong>Weight Initialize</strong></p>
<p>初始参数设置过小，神经元容易崩溃；初始参数设置过大，神经元容易饱和。为了解决这个问题，提出了<code>Xavier</code>初始化，其在标准高斯分布里采样，并补偿了输入连接数<code>fan_in</code>带来的方差放大效应。</p>
<pre class="language-python" data-language="python"><code class="language-python">w <span class="token operator">=</span> np<span class="token punctuation">.</span>random<span class="token punctuation">.</span>randn<span class="token punctuation">(</span>fan_in<span class="token punctuation">,</span>fan_out<span class="token punctuation">)</span><span class="token operator">/</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>fan_in<span class="token punctuation">)</span></code></pre>
<p><strong>BatchNorm</strong> <span class="math display">$$
\frac{x-E(X)}{\sqrt{var x}}
$$</span>
即<code>Z-Score</code>标准化的公式，一般在卷积层后进行归一化，统一输入值的分布。</p>
<p>对于 <code>(N, C, H, W)</code>
的卷积网络特征图，本质上是在一个批次的所有样本的同一个通道上做归一化，计算的是
<code>N*H*W</code>
个元素的均值和方差，在<code>CV</code>领域应用较多。而<code>LayerNorm</code>本质上是对单个样本的所有特征做归一化，计算的是
<code>C*H*W</code>
个元素的均值和方差，在<code>NLP</code>领域应用较多。</p>
<p><strong>Regularization</strong></p>
<p>正则化方法有很多，主要包括以下几种：集成学习（训练多个模型预测取平均值防止过拟合提升性能）；<code>Dropout</code>，随机选取失活神经元（激活函数值设为<code>0</code>）
随机性；<code>batch normalization</code>，噪声 <span class="math inline"><em>y</em> = <em>f</em><sub><em>W</em></sub>(<em>x</em>, <em>z</em>)</span>，<span class="math inline"><em>y</em> = <em>f</em>(<em>x</em>) = <em>E</em><sub><em>z</em></sub>[<em>f</em>(<em>x</em>, <em>z</em>)] = ∫<em>p</em>(<em>z</em>)<em>f</em>(<em>x</em>, <em>z</em>)<em>d</em><em>z</em></span>；<code>data augmentation</code>，随机转换（翻转/剪切/放缩/旋转/…）；<code>drop connect</code>，随机丢弃网络连接；<code>fractional max pooling</code>，使用随机大小的池化区域；<code>stochastic depth</code>，在训练时随机跳过某些层。</p>
<p><strong>Transfer learning</strong></p>
<p>例如在<code>ImageNet</code>上预训练，然后修改输出维度/网络层数，帮助自己的样本进行训练。</p>
<h2 id="附录2-classification-code">附录2 Classification Code</h2>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># train.py</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data <span class="token keyword">import</span> DataLoader
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter
<span class="token keyword">import</span> time

<span class="token comment"># 定义训练设备</span>
device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span>

<span class="token comment"># 定义数据变换和增强</span>
train_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 调整图像大小</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomCrop<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 随机裁剪</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 随机水平翻转</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span>degrees<span class="token operator">=</span><span class="token number">15</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 随机旋转</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> contrast<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> saturation<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> hue<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 颜色抖动</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>RandomGrayscale<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 随机灰度化</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 转换为张量</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.4914</span><span class="token punctuation">,</span> <span class="token number">0.4822</span><span class="token punctuation">,</span> <span class="token number">0.4465</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.2023</span><span class="token punctuation">,</span> <span class="token number">0.1994</span><span class="token punctuation">,</span> <span class="token number">0.2010</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># CIFAR10标准化</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

test_transform <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 调整图像大小</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>  <span class="token comment"># 转换为张量</span>
    torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">0.4914</span><span class="token punctuation">,</span> <span class="token number">0.4822</span><span class="token punctuation">,</span> <span class="token number">0.4465</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">0.2023</span><span class="token punctuation">,</span> <span class="token number">0.1994</span><span class="token punctuation">,</span> <span class="token number">0.2010</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># CIFAR10标准化</span>
<span class="token punctuation">]</span><span class="token punctuation">)</span>

<span class="token comment"># 准备数据集</span>
train_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'../dataset'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>train_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
test_data <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>CIFAR10<span class="token punctuation">(</span><span class="token string">'../dataset'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> transform<span class="token operator">=</span>test_transform<span class="token punctuation">,</span>download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>

train_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_data<span class="token punctuation">)</span>
test_data_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>test_data<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>train_data_size<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>test_data_size<span class="token punctuation">)</span>

<span class="token comment"># 打包数据</span>
train_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>
test_dataloader <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">)</span>

<span class="token comment"># 创建网络模型 </span>
<span class="token keyword">class</span> <span class="token class-name">CIF</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CIF<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
cif <span class="token operator">=</span> CIF<span class="token punctuation">(</span><span class="token punctuation">)</span>
cif<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 损失函数</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> loss_fn<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

<span class="token comment"># 优化器</span>
learning_rate <span class="token operator">=</span> <span class="token number">1e-2</span>  <span class="token comment"># 1x(10)^(-2)</span>
optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>cif<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span>learning_rate<span class="token punctuation">)</span>

<span class="token comment"># 记录训练次数</span>
total_train_step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment"># 记录测试的次数</span>
total_test_step <span class="token operator">=</span> <span class="token number">0</span>
<span class="token comment"># 训练的轮数</span>
epoch <span class="token operator">=</span> <span class="token number">10</span>
<span class="token comment"># 添加tensorboard</span>
writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">'../logs'</span><span class="token punctuation">)</span>
<span class="token comment"># 计算开始时间</span>
start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>

<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'-----------第&#123;&#125;轮训练开始------------'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i <span class="token operator">+</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
    cif<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 和cif.eval()只对部分网络有用（dropout等）</span>
    <span class="token keyword">for</span> data <span class="token keyword">in</span> train_dataloader<span class="token punctuation">:</span>
        imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data
        imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        output <span class="token operator">=</span> cif<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>output<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>

        <span class="token comment"># 优化器调优</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

        total_train_step <span class="token operator">=</span> total_train_step <span class="token operator">+</span> <span class="token number">1</span>
        <span class="token keyword">if</span> total_train_step <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>  <span class="token comment"># 每100次打印一次</span>
            end_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练时长:&#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>end_time <span class="token operator">-</span> start_time<span class="token punctuation">)</span><span class="token punctuation">)</span>  
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'训练次数：&#123;&#125;, loss: &#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_train_step<span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
            writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'train_loss'</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> total_train_step<span class="token punctuation">)</span>
            
    <span class="token comment"># 测试步骤开始</span>
    cif<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
    total_test_loss <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 损失指标</span>
    total_accuracy <span class="token operator">=</span> <span class="token number">0</span>  <span class="token comment"># 准确率指标</span>
    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">for</span> data <span class="token keyword">in</span> test_dataloader<span class="token punctuation">:</span>
            imgs<span class="token punctuation">,</span> targets <span class="token operator">=</span> data
            imgs <span class="token operator">=</span> imgs<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            targets <span class="token operator">=</span> targets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
            outputs <span class="token operator">=</span> cif<span class="token punctuation">(</span>imgs<span class="token punctuation">)</span>
            loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>outputs<span class="token punctuation">,</span> targets<span class="token punctuation">)</span>
            accuracy <span class="token operator">=</span> <span class="token punctuation">(</span>outputs<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> targets<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">sum</span><span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 1为横着方向,返回每一行最大的索引，True则返回1</span>
            total_test_loss <span class="token operator">=</span> total_test_loss <span class="token operator">+</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span>
            total_accuracy <span class="token operator">=</span> total_accuracy <span class="token operator">+</span> accuracy

    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'整体测试集上的loss：&#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_test_loss<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'整体测试集上的正确率：&#123;&#125;'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>total_accuracy <span class="token operator">/</span> test_data_size<span class="token punctuation">)</span><span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'test_loss'</span><span class="token punctuation">,</span> total_test_loss<span class="token punctuation">,</span> total_test_step<span class="token punctuation">)</span>
    writer<span class="token punctuation">.</span>add_scalar<span class="token punctuation">(</span><span class="token string">'test_accuracy'</span><span class="token punctuation">,</span> total_accuracy <span class="token operator">/</span> test_data_size<span class="token punctuation">,</span> total_test_step<span class="token punctuation">)</span>
    total_test_step <span class="token operator">=</span> total_test_step <span class="token operator">+</span> <span class="token number">1</span>

    <span class="token comment"># 保存模型</span>
    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>cif<span class="token punctuation">,</span> <span class="token string">'cif_&#123;&#125;.pth'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>i<span class="token punctuation">)</span><span class="token punctuation">)</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'模型已保存'</span><span class="token punctuation">)</span>

writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token comment"># tensorboard --logdir=logs --port=6007</span></code></pre>
<pre class="language-python" data-language="python"><code class="language-python"><span class="token comment"># test.py</span>
<span class="token keyword">import</span> torch
<span class="token keyword">import</span> torchvision
<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image
<span class="token keyword">from</span> torch <span class="token keyword">import</span> nn
<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>tensorboard <span class="token keyword">import</span> SummaryWriter

img_path <span class="token operator">=</span> <span class="token string">'../dataset/train/dog/dog.jpg'</span>
img <span class="token operator">=</span> Image<span class="token punctuation">.</span><span class="token builtin">open</span><span class="token punctuation">(</span>img_path<span class="token punctuation">)</span>
image <span class="token operator">=</span> img<span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>

transforms <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span>
    <span class="token punctuation">[</span>torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>Resize<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span> torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
image <span class="token operator">=</span> transforms<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token comment"># print(image.shape)</span>

<span class="token keyword">class</span> <span class="token class-name">CIF</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>CIF<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> padding<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span>kernel_size<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Conv2d<span class="token punctuation">(</span><span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">5</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>MaxPool2d<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Flatten<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">,</span> <span class="token number">64</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
            nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>
        <span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x

writer <span class="token operator">=</span> SummaryWriter<span class="token punctuation">(</span><span class="token string">'../logs'</span><span class="token punctuation">)</span>
model <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span><span class="token string">'../code/cif_9.pth'</span><span class="token punctuation">,</span>map_location<span class="token operator">=</span>torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">'cpu'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>model<span class="token punctuation">)</span>
image <span class="token operator">=</span> torch<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span>image<span class="token punctuation">,</span> <span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> <span class="token number">3</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">,</span> <span class="token number">32</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
model<span class="token punctuation">.</span><span class="token builtin">eval</span><span class="token punctuation">(</span><span class="token punctuation">)</span>
<span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    output <span class="token operator">=</span> model<span class="token punctuation">(</span>image<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">)</span>
<span class="token keyword">print</span><span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>add_graph<span class="token punctuation">(</span>CIF<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> image<span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>add_image<span class="token punctuation">(</span><span class="token string">'CIF'</span><span class="token punctuation">,</span> image<span class="token punctuation">,</span> dataformats<span class="token operator">=</span><span class="token string">'NCHW'</span><span class="token punctuation">)</span>
writer<span class="token punctuation">.</span>close<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Sa1ntCHEN</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="https://saintcen.github.io/2025/11/08/Computer%20Vision/">https://saintcen.github.io/2025/11/08/Computer%20Vision/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Sa1ntCHEN</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            
                                <a href="/tags/AI/">
                                    <span class="chip bg-color">AI</span>
                                </a>
                            
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.jpg" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="far fa-dot-circle"></i>&nbsp;本篇
            </div>
            <div class="card">
                <a href="/2025/11/08/Computer%20Vision/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/1.jpg" class="responsive-img" alt="Computer Vision">
                        
                        <span class="card-title">Computer Vision</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-08
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%AC%94%E8%AE%B0/" class="post-category">
                                    笔记
                                </a>
                            
                            
                        </span>
                    </div>
                </div>

                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AI/">
                        <span class="chip bg-color">AI</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2025/11/06/3DGS%E5%8E%9F%E7%90%86&%E8%BF%90%E8%A1%8C/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/2.jpg" class="responsive-img" alt="3DGS原理&amp;运行">
                        
                        <span class="card-title">3DGS原理&amp;运行</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2025-11-06
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-bookmark fa-fw icon-category"></i>
                            
                            <a href="/categories/%E7%A7%91%E7%A0%94/" class="post-category">
                                    科研
                                </a>
                            
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/AI/">
                        <span class="chip bg-color">AI</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>


  <!-- 是否加载使用自带的 prismjs. -->
  <script type="text/javascript" src="/libs/prism/prism.min.js"></script>


<!-- 代码语言 -->

<script type="text/javascript" src="/libs/codeBlock/codeLang.js"></script>


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->

<script type="text/javascript" src="/libs/codeBlock/codeShrink.js"></script>




    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>


<script src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
<script>
    MathJax.Hub.Config({
        tex2jax: {inlineMath: [['$', '$'], ['\\(', '\\)']]}
    });
</script>



    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="tencent"
                   type="playlist"
                   id="2870668388"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="/libs/aplayer/Meting.min.js"></script>

    

    <div class="container row center-align"
         style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2019-2025</span>
            
            <a href="/about" target="_blank">Sa1ntCHEN</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            
            <br>
            
            
            
                
            
            
                <span id="busuanzi_container_site_pv">
                &nbsp;|&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;
                    <span id="busuanzi_value_site_pv" class="white-color"></span>
            </span>
            
            
                <span id="busuanzi_container_site_uv">
                &nbsp;|&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;
                    <span id="busuanzi_value_site_uv" class="white-color"></span>
            </span>
            
            <br>

            <!-- 运行天数提醒. -->
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/SaintCEN" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:24009300521@stu.xidian.edu.cn" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=2587899960" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 2587899960" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 白天和黑夜主题 -->
<div class="stars-con">
    <div id="stars"></div>
    <div id="stars2"></div>
    <div id="stars3"></div>  
</div>

<script>
    function switchNightMode() {
        $('<div class="Cuteen_DarkSky"><div class="Cuteen_DarkPlanet"></div></div>').appendTo($('body')),
        setTimeout(function () {
            $('body').hasClass('DarkMode') 
            ? ($('body').removeClass('DarkMode'), localStorage.setItem('isDark', '0'), $('#sum-moon-icon').removeClass("fa-sun").addClass('fa-moon')) 
            : ($('body').addClass('DarkMode'), localStorage.setItem('isDark', '1'), $('#sum-moon-icon').addClass("fa-sun").removeClass('fa-moon')),
            
            setTimeout(function () {
            $('.Cuteen_DarkSky').fadeOut(1e3, function () {
                $(this).remove()
            })
            }, 2e3)
        })
    }
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/lightgallery/1.10.0/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    

    
    
    

    <!-- 雪花特效 -->
    

    <!-- 鼠标星星特效 -->
    

     
        <script src="https://ssl.captcha.qq.com/TCaptcha.js"></script>
        <script src="/libs/others/TencentCaptcha.js"></script>
        <button id="TencentCaptcha" data-appid="xxxxxxxxxx" data-cbfn="callback" type="button" hidden></button>
    

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
